{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neurais Recorrentes (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T11:22:24.364032Z",
     "start_time": "2021-02-01T11:22:21.731822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T11:22:24.370594Z",
     "start_time": "2021-02-01T11:22:24.366802Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN básica - implementação manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T11:22:24.703392Z",
     "start_time": "2021-02-01T11:22:24.376219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/liliane-hop/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X0 = tf.compat.v1.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.compat.v1.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "Wx = tf.Variable(tf.compat.v1.random_normal(shape=[n_inputs, n_neurons], dtype=tf.float32))\n",
    "Wy = tf.Variable(tf.compat.v1.random_normal(shape=[n_neurons, n_neurons], dtype=tf.float32))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons], dtype=tf.float32))\n",
    "\n",
    "Y0 = tf.math.tanh(tf.matmul(X0, Wx) + b)\n",
    "Y1 = tf.math.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "X0_batch = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]]) # t = 0\n",
    "X1_batch = np.array([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]]) # t = 1\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saída da rede em ambos intervalos para todos os neurônios e todas as instâncias no minilote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T11:22:24.717762Z",
     "start_time": "2021-02-01T11:22:24.710380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.08133698  0.9461138   0.9992334  -0.5767777  -0.99837404]\n",
      " [-0.99998575 -0.93964344  1.         -0.9999966  -1.        ]\n",
      " [-1.         -0.9999464   1.         -1.         -1.        ]\n",
      " [-1.         -1.          0.99999994 -1.         -1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(Y0_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T11:22:24.823997Z",
     "start_time": "2021-02-01T11:22:24.720814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.         -1.          1.         -1.         -1.        ]\n",
      " [-0.758769   -0.95284617 -0.31331128  0.65702546 -0.9547951 ]\n",
      " [-1.         -1.          1.         -1.         -1.        ]\n",
      " [-0.99999833 -0.9999989   0.9999974  -0.99975085 -0.9999885 ]]\n"
     ]
    }
   ],
   "source": [
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desenrolamento estático através do tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T11:22:25.041641Z",
     "start_time": "2021-02-01T11:22:24.831659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-f473b0140bcd>:9: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-6-f473b0140bcd>:10: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/liliane-hop/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/liliane-hop/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X0 = tf.compat.v1.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.compat.v1.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "basic_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.compat.v1.nn.static_rnn(basic_cell, [X0, X1], dtype=tf.float32)\n",
    "Y0, Y1 = output_seqs\n",
    "\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "X0_batch = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]])\n",
    "X1_batch = np.array([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]])\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T11:22:25.164246Z",
     "start_time": "2021-02-01T11:22:25.044921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5602356  -0.151552   -0.13176677 -0.23124242  0.7767599 ]\n",
      " [-0.58441734 -0.94278073 -0.31290483 -0.63624394  0.99970096]\n",
      " [-0.96195525 -0.9976481  -0.47382185 -0.8533018   0.9999997 ]\n",
      " [-0.99984044 -0.9999935  -0.39269054 -0.7114957   0.99999505]]\n"
     ]
    }
   ],
   "source": [
    "print(Y0_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T11:22:25.508454Z",
     "start_time": "2021-02-01T11:22:25.170615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.9992447  -0.99997085 -0.79857796 -0.8924509   1.        ]\n",
      " [ 0.1243832  -0.5071309  -0.6011743   0.26781803  0.90067124]\n",
      " [-0.99676526 -0.998416   -0.6972026  -0.23852691  0.99999946]\n",
      " [-0.9585109  -0.9515962  -0.5853359   0.17232035  0.99946636]]\n"
     ]
    }
   ],
   "source": [
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desenrolamento dinâmico através do tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T11:22:25.954123Z",
     "start_time": "2021-02-01T11:22:25.514345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-d4f8e4306e00>:10: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "[[[ 0.8737009  -0.695371   -0.16444561 -0.5569858  -0.00353421]\n",
      "  [ 0.9999996  -0.99998724 -0.84644794 -0.9953022  -0.992788  ]]\n",
      "\n",
      " [[ 0.9995603  -0.995603   -0.70460784 -0.9454561  -0.8067972 ]\n",
      "  [ 0.27718204 -0.21497945  0.8087338  -0.4887352   0.4198085 ]]\n",
      "\n",
      " [[ 0.9999985  -0.9999461  -0.9196625  -0.99448997 -0.97723144]\n",
      "  [ 0.9998222  -0.9989662  -0.1431439  -0.9796231  -0.95658356]]\n",
      "\n",
      " [[ 0.91071117 -0.9851721   0.65366745  0.9754118  -0.88200337]\n",
      "  [ 0.9858268  -0.5021983   0.3248572  -0.6346006  -0.50137085]]]\n"
     ]
    }
   ],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "X = tf.compat.v1.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "basic_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.compat.v1.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "X_batch = np.array([\n",
    "        [[0, 1, 2], [9, 8, 7]], # instância 1\n",
    "        [[3, 4, 5], [0, 0, 0]], # instância 2\n",
    "        [[6, 7, 8], [6, 5, 4]], # instância 3\n",
    "        [[9, 0, 1], [3, 2, 1]], # instância 4\n",
    "    ])\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})\n",
    "\n",
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulando sentenças de entrada de comprimento variável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T11:22:26.204891Z",
     "start_time": "2021-02-01T11:22:25.957012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.00294726  0.40077475 -0.81542796 -0.34734768  0.49147463]\n",
      "  [-0.96901876 -0.99999523 -1.          0.96501315  0.9936624 ]]\n",
      "\n",
      " [[-0.74088514 -0.93418354 -0.9999301   0.33584136  0.9490635 ]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.9569023  -0.9990097  -1.          0.78613037  0.9960017 ]\n",
      "  [-0.71336406 -0.9999559  -0.9999992   0.7000074   0.9899887 ]]\n",
      "\n",
      " [[-0.99721456 -0.9998737  -0.99991035  0.9902564   0.9975323 ]\n",
      "  [ 0.00871231 -0.99722683 -0.9977773   0.0639837   0.883115  ]]]\n"
     ]
    }
   ],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "X = tf.compat.v1.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "seq_length = tf.compat.v1.placeholder(tf.int32, [None])\n",
    "\n",
    "basic_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.compat.v1.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32, sequence_length=seq_length)\n",
    "\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "X_batch = np.array([\n",
    "        #step 0     step 1\n",
    "        [[0, 1, 2], [9, 8, 7]], # instância 1\n",
    "        [[3, 4, 5], [0, 0, 0]], # instância 2 (preenchido com vetor de zeros)\n",
    "        [[6, 7, 8], [6, 5, 4]], # instância 3\n",
    "        [[9, 0, 1], [3, 2, 1]], # instância 4\n",
    "    ])\n",
    "\n",
    "seq_length_batch = np.array([2, 1, 2, 2])\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run([outputs, states], feed_dict={X: X_batch, seq_length: seq_length_batch})\n",
    "\n",
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando um classificador de sequência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T11:22:26.572948Z",
     "start_time": "2021-02-01T11:22:26.208042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-11-905f5fa067ca>:16: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/liliane-hop/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "n_steps = 28\n",
    "n_inputs = 28\n",
    "n_neurons = 150\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "X = tf.compat.v1.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.compat.v1.placeholder(tf.int32, [None])\n",
    "\n",
    "basic_cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.compat.v1.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "\n",
    "logits = tf.compat.v1.layers.dense(states, n_outputs)\n",
    "xentropy = tf.compat.v1.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.compat.v1.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.compat.v1.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T11:22:27.280290Z",
     "start_time": "2021-02-01T11:22:26.576403Z"
    }
   },
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch\n",
    "        \n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]\n",
    "\n",
    "X_test = X_test.reshape((-1, n_steps, n_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T11:34:44.234070Z",
     "start_time": "2021-02-01T11:22:27.283251Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Last batch accuracy: 0.91333336 Test accuracy: 0.9279\n",
      "10 Last batch accuracy: 0.96 Test accuracy: 0.965\n",
      "20 Last batch accuracy: 0.9866667 Test accuracy: 0.9775\n",
      "30 Last batch accuracy: 0.9866667 Test accuracy: 0.9749\n",
      "40 Last batch accuracy: 1.0 Test accuracy: 0.9752\n",
      "50 Last batch accuracy: 0.99333334 Test accuracy: 0.9743\n",
      "60 Last batch accuracy: 0.99333334 Test accuracy: 0.9778\n",
      "70 Last batch accuracy: 0.97333336 Test accuracy: 0.9731\n",
      "80 Last batch accuracy: 1.0 Test accuracy: 0.9805\n",
      "90 Last batch accuracy: 0.99333334 Test accuracy: 0.9784\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 150\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 10 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "            print(epoch, 'Last batch accuracy:', acc_batch, 'Test accuracy:', acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T11:10:57.345785Z",
     "start_time": "2021-02-01T11:10:57.342794Z"
    }
   },
   "source": [
    "### Prevendo Séries temporais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T11:36:40.559967Z",
     "start_time": "2021-02-01T11:36:40.542579Z"
    }
   },
   "outputs": [],
   "source": [
    "t_min, t_max = 0, 30\n",
    "resolution = 0.1\n",
    "\n",
    "def time_series(t):\n",
    "    return t * np.sin(t) / 3 + 2 * np.sin(t*5)\n",
    "\n",
    "def next_batch(batch_size, n_steps):\n",
    "    t0 = np.random.rand(batch_size, 1) * (t_max - t_min - n_steps * resolution)\n",
    "    Ts = t0 + np.arange(0., n_steps + 1) * resolution\n",
    "    ys = time_series(Ts)\n",
    "    return ys[:, :-1].reshape(-1, n_steps, 1), ys[:, 1:].reshape(-1, n_steps, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T11:37:01.406736Z",
     "start_time": "2021-02-01T11:36:49.373706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \tMSE: 17.23357\n",
      "100 \tMSE: 0.64479566\n",
      "200 \tMSE: 0.22471042\n",
      "300 \tMSE: 0.08508409\n",
      "400 \tMSE: 0.06518517\n",
      "500 \tMSE: 0.048398558\n",
      "600 \tMSE: 0.049764246\n",
      "700 \tMSE: 0.063373424\n",
      "800 \tMSE: 0.051421843\n",
      "900 \tMSE: 0.050426837\n",
      "1000 \tMSE: 0.047503926\n",
      "1100 \tMSE: 0.05374335\n",
      "1200 \tMSE: 0.051288188\n",
      "1300 \tMSE: 0.03611956\n",
      "1400 \tMSE: 0.047032144\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "n_steps = 20\n",
    "n_inputs = 1\n",
    "n_neurons = 100\n",
    "\n",
    "X = tf.compat.v1.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "y = tf.compat.v1.placeholder(tf.float32, [None, n_steps, n_outputs])\n",
    "\n",
    "cell = tf.compat.v1.nn.rnn_cell.BasicRNNCell(num_units=n_neurons, activation=tf.nn.relu)\n",
    "rnn_outputs, states = tf.compat.v1.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "n_outputs = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons])\n",
    "stacked_outputs = tf.compat.v1.layers.dense(stacked_rnn_outputs, n_outputs)\n",
    "outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(outputs - y))\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "saver = tf.compat.v1.train.Saver()\n",
    "\n",
    "n_iterations = 1500\n",
    "batch_size = 50\n",
    "t_instance = np.linspace(12.2, 12.2 + resolution * (n_steps + 1), n_steps + 1)\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        X_batch, y_batch = next_batch(batch_size, n_steps)\n",
    "        sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if iteration % 100 == 0:\n",
    "            mse = loss.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            print(iteration, '\\tMSE:', mse)\n",
    "    \n",
    "    X_new = time_series(np.array(t_instance[:-1].reshape(-1, n_steps, n_inputs)))\n",
    "    y_pred = sess.run(outputs, feed_dict={X: X_new})    \n",
    "    saver.save(sess, 'model/my_time_series_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T11:37:12.396020Z",
     "start_time": "2021-02-01T11:37:12.388217Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-3.4835126],\n",
       "        [-2.5070946],\n",
       "        [-1.1347352],\n",
       "        [ 0.6665767],\n",
       "        [ 1.9816937],\n",
       "        [ 3.0658002],\n",
       "        [ 3.5624275],\n",
       "        [ 3.3560722],\n",
       "        [ 2.8085177],\n",
       "        [ 2.1856112],\n",
       "        [ 1.7481649],\n",
       "        [ 1.5522208],\n",
       "        [ 1.8859161],\n",
       "        [ 2.7251291],\n",
       "        [ 3.87829  ],\n",
       "        [ 5.0895925],\n",
       "        [ 6.1035843],\n",
       "        [ 6.679761 ],\n",
       "        [ 6.662667 ],\n",
       "        [ 6.0519094]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
